@page "/speech"
@using AIChat.Models
@using AIChat.Services

@inject IJSRuntime JS
@inject SpeechService SpeechService

@rendermode InteractiveServer

@implements IDisposable

<h3 class="speech-title">Speech Translator</h3>

<div class="speech-container">
    <div class="speech-controls">
        <div class="speech-row">
            <label for="targetLang" class="speech-label">Target Language</label>
            <select id="targetLang" class="speech-select" @bind="TargetLang">
                <option value="ta">Tamil</option>
                <option value="hi">Hindi</option>
                <option value="fr">French</option>
                <option value="de">German</option>
                <option value="ar">Arabic</option>
            </select>
        </div>
        <div class="speech-row search-bar-row">
            <input class="speech-search-input" @bind="TypedText" @onkeydown="OnInputKeyDown" placeholder="Type or speak in English..." />
            <button class="btn speech-mic-btn" @onclick="RecordAsync">
                <span>@(IsListening ? "🎤" : "🎙️")</span>
            </button>
            <button class="btn btn-primary speech-search-btn" @onclick="TranslateTypedText" disabled="@IsListening || string.IsNullOrWhiteSpace(TypedText)">Translate</button>
        </div>
        <div class="speech-row">
            <audio controls @ref="audioRef" src="@AudioUrl" type="audio/wav"></audio>
        </div>
    </div>
    <div class="speech-messages">
        <ul class="speech-list">
            @foreach (var item in Messages)
            {
                <li class="speech-list-item">
                    <b>🗣️ You:</b> @item.Original <br />
                    <b>🌐 Translated:</b> @item.Translated
                </li>
            }
        </ul>
    </div>
</div>

<style>
.speech-container {
    max-width: 600px;
    margin: auto;
    padding: 20px;
    background: #fff;
    border-radius: 12px;
    box-shadow: 0 2px 8px rgba(0,0,0,0.04);
    display: flex;
    flex-direction: column;
    gap: 18px;
}
.speech-title {
    text-align: center;
    color: #0d6efd;
    font-size: 1.7rem;
    font-weight: bold;
    margin-bottom: 24px;
}
.speech-controls {
    display: flex;
    flex-direction: column;
    gap: 12px;
    margin-bottom: 10px;
}
.speech-row {
    display: flex;
    align-items: center;
    gap: 12px;
}
.speech-label {
    font-weight: 500;
    color: #0d6efd;
    margin-right: 8px;
}
.speech-select {
    padding: 6px 12px;
    border-radius: 6px;
    border: 1px solid #ccc;
    font-size: 1rem;
}
.speech-search-input {
    flex: 1;
    padding: 8px 12px;
    border-radius: 6px;
    border: 1px solid #ccc;
    font-size: 1.1rem;
    outline: none;
}
.speech-mic-btn {
    background: #fff;
    border: 1px solid #0d6efd;
    color: #0d6efd;
    border-radius: 50%;
    width: 44px;
    height: 44px;
    font-size: 1.3rem;
    display: flex;
    align-items: center;
    justify-content: center;
    margin-left: 4px;
    margin-right: 4px;
    transition: background 0.2s;
}
.speech-mic-btn:disabled {
    opacity: 0.6;
}
.speech-mic-btn:hover:not(:disabled) {
    background: #e7f1ff;
}
.speech-search-btn {
    min-width: 100px;
    background-color: #0d6efd;
    border-color: #0d6efd;
    color: #fff;
    font-weight: 500;
    border-radius: 6px;
    padding: 8px 16px;
    transition: background 0.2s;
}
.speech-search-btn:disabled {
    opacity: 0.6;
}
.speech-search-btn:hover:not(:disabled) {
    background-color: #0b5ed7;
    border-color: #0a58ca;
}
.speech-messages {
    height: 320px;
    overflow-y: auto;
    background: #f8f9fa;
    border-radius: 8px;
    padding: 14px;
    box-shadow: 0 1px 4px rgba(0,0,0,0.03);
}
.speech-list {
    list-style: none;
    padding: 0;
    margin: 0;
}
.speech-list-item {
    margin-bottom: 16px;
    padding-bottom: 8px;
    border-bottom: 1px solid #e3e3e3;
    color: #333;
}
.speech-list-item:last-child {
    border-bottom: none;
}
.speech-row audio {
    width: 100%;
    border-radius: 6px;
    background: #e9ecef;
}
.search-bar-row {
    margin-top: 8px;
    margin-bottom: 8px;
    width: 100%;
}
</style>

@code {
    private DotNetObjectReference<Speech>? dotNetHelper;
    private string TargetLang { get; set; } = "ta";
    private string TypedText { get; set; } = string.Empty;
    private bool IsListening { get; set; } = false;
    private List<ChatItem> Messages { get; set; } = new();
    private string AudioUrl { get; set; }
    private ElementReference audioRef;

    private List<string> Languages = new List<string>
    {
        "en", "ta", "fr", "de", "es", "hi", "te", "ml", "zh"
    };

    protected override void OnInitialized()
    {
        dotNetHelper = DotNetObjectReference.Create(this);
    }

    private async Task RecordAsync()
    {
        if(IsListening)
        {
            await JS.InvokeVoidAsync("stopRecording", dotNetHelper);
        }
        else
        {
            await JS.InvokeVoidAsync("startRecording");
        }
        IsListening = !IsListening;
    }

    [JSInvokable("OnAudioCaptured")]
    public async Task OnAudioCaptured(string base64Audio)
    {
        var result = await SpeechService.ProcessAudioAsync(base64Audio, TargetLang);
        Messages.Add(new ChatItem(result.RecognizedText, result.TranslatedText));
        await PlayAudio(result.Audio);

        StateHasChanged();
    }

    private async Task TranslateTypedText()
    {
        if (string.IsNullOrWhiteSpace(TypedText)) return;
        try
        {
            var response = await SpeechService.TranslateTextAsync(TypedText, TargetLang);
            Messages.Add(new ChatItem(response.RecognizedText, response.TranslatedText));
            await PlayAudio(response.Audio);
            TypedText = string.Empty;
        }
        catch (Exception ex)
        {
            Messages.Add(new ChatItem("❌ Error", ex.Message));
            await InvokeAsync(StateHasChanged);
        }
    }

    private async Task PlayAudio(byte[]? audioData)
    {
        if (audioData != null && audioData.Length > 0)
        {
            AudioUrl = $"data:audio/wav;base64,{Convert.ToBase64String(audioData)}";
            await InvokeAsync(StateHasChanged);
            await Task.Delay(100);
            await JS.InvokeVoidAsync("audioInterop.playAudio", audioRef);
        }
        else
        {
            AudioUrl = null;
        }
    }

    private async Task OnInputKeyDown(KeyboardEventArgs e)
    {
        if (e.Key == "Enter")
        {
            await TranslateTypedText();
        }
    }

    public void Dispose()
    {
        dotNetHelper?.Dispose();
    }
}
